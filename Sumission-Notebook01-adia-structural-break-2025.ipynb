{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install antropy --quiet\n!pip install PyWavelets --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T23:32:43.691016Z","iopub.execute_input":"2025-09-05T23:32:43.691384Z","iopub.status.idle":"2025-09-05T23:32:53.621004Z","shell.execute_reply.started":"2025-09-05T23:32:43.691352Z","shell.execute_reply":"2025-09-05T23:32:53.619419Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"%pip install crunch-cli --upgrade --quiet --progress-bar off\n!crunch setup-notebook structural-break vpZXd9oUlwMy6GhLU36kHqPf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7DUeixiC_IJM","outputId":"acc1a734-d506-4a0f-b234-59436c8d7683","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T23:32:53.623225Z","iopub.execute_input":"2025-09-05T23:32:53.623691Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup","metadata":{"id":"EpLeMWSw-0fQ"}},{"cell_type":"code","source":"import os\nimport typing\n\n# Import your dependencies\nimport joblib\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport sklearn.metrics\nfrom scipy.stats import wasserstein_distance  # 1D Earth Mover's Distance\n\nimport warnings\nfrom scipy.signal import welch\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning)","metadata":{"ExecuteTime":{"end_time":"2024-11-18T09:52:21.302334Z","start_time":"2024-11-18T09:52:18.268241Z"},"id":"MKqz-6Zw-0fR","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:32:15.129994Z","iopub.execute_input":"2025-09-05T19:32:15.130967Z","iopub.status.idle":"2025-09-05T19:32:15.137680Z","shell.execute_reply.started":"2025-09-05T19:32:15.130922Z","shell.execute_reply":"2025-09-05T19:32:15.136491Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"import crunch\n\n# Load the Crunch Toolings\ncrunch = crunch.load_notebook()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xjD_WSAS-0fR","outputId":"75b022d0-b3ae-4c07-e136-8ea22537731f","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:32:20.926991Z","iopub.execute_input":"2025-09-05T19:32:20.927379Z","iopub.status.idle":"2025-09-05T19:32:20.933625Z","shell.execute_reply.started":"2025-09-05T19:32:20.927353Z","shell.execute_reply":"2025-09-05T19:32:20.932641Z"}},"outputs":[{"name":"stdout","text":"loaded inline runner with module: <module '__main__'>\n\ncli version: 7.4.0\navailable ram: 31.35 gb\navailable cpu: 4 core\n----\n","output_type":"stream"}],"execution_count":63},{"cell_type":"code","source":"# Load the data simply\nX_train, y_train, X_test = crunch.load_data()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RKHXgvjN-0fS","outputId":"3b7ef5e2-8db7-4d30-ff24-6acc894920b7","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T19:32:26.663032Z","iopub.execute_input":"2025-09-05T19:32:26.664070Z","iopub.status.idle":"2025-09-05T19:32:30.498022Z","shell.execute_reply.started":"2025-09-05T19:32:26.664007Z","shell.execute_reply":"2025-09-05T19:32:30.496860Z"}},"outputs":[{"name":"stdout","text":"data/X_train.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/X_train.parquet (204327238 bytes)\ndata/X_train.parquet: already exists, file length match\ndata/X_test.reduced.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/X_test.reduced.parquet (2380918 bytes)\ndata/X_test.reduced.parquet: already exists, file length match\ndata/y_train.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/y_train.parquet (61003 bytes)\ndata/y_train.parquet: already exists, file length match\ndata/y_test.reduced.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/y_test.reduced.parquet (2655 bytes)\ndata/y_test.reduced.parquet: already exists, file length match\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T18:06:28.999954Z","iopub.execute_input":"2025-09-05T18:06:29.000369Z","iopub.status.idle":"2025-09-05T18:06:29.013087Z","shell.execute_reply.started":"2025-09-05T18:06:29.000342Z","shell.execute_reply":"2025-09-05T18:06:29.011558Z"}},"outputs":[{"name":"stdout","text":"(23715734, 2)\nstructural_breakpoint\nFalse    7092\nTrue     2909\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"print(\"Number of datasets:\", len(X_test))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ErbKAs--0fT","outputId":"5ce46294-1824-4067-be90-547189e90be3","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T18:06:47.924594Z","iopub.execute_input":"2025-09-05T18:06:47.924961Z","iopub.status.idle":"2025-09-05T18:06:47.931023Z","shell.execute_reply.started":"2025-09-05T18:06:47.924929Z","shell.execute_reply":"2025-09-05T18:06:47.930082Z"}},"outputs":[{"name":"stdout","text":"Number of datasets: 101\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"### ðŸ”¥ train.py","metadata":{}},{"cell_type":"code","source":"%%writefile main.py\n\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import skew, kurtosis, ks_2samp, mannwhitneyu, wasserstein_distance\nfrom scipy.signal import welch, hilbert\nfrom statsmodels.tsa.stattools import acf, pacf\n# ======= Refactor-friendly train() and infer() =======\nimport os\nimport joblib\nimport numpy as np\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.calibration import CalibratedClassifierCV\n\nimport warnings\nfrom sklearn.exceptions import ConvergenceWarning\n\n# Suppress convergence warnings\nwarnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\nwarnings.filterwarnings(\"ignore\", category=UserWarning)  # suppress welch nperseg warnings\n\n# optional libs - safe to import if installed\ntry:\n    import antropy as ant\nexcept Exception:\n    ant = None\ntry:\n    import pywt\nexcept Exception:\n    pywt = None\n\n# --- helper funcs (robust + small fixes) ---\n# ---### ðŸ”¥ Advanced Feature Engineering Function-----\ndef compute_permutation_entropy(x, m=3, tau=1):\n    if ant is None or len(x) < (m + 1):\n        return np.nan\n    try:\n        return float(ant.perm_entropy(x, order=m, delay=tau, normalize=True))\n    except Exception:\n        return np.nan\n\ndef compute_multiscale_entropy(x, scales=(2,3,5)):\n    if ant is None:\n        return np.nan\n    vals = []\n    for s in scales:\n        xs = x[::s]\n        if len(xs) > 10:\n            try:\n                vals.append(float(ant.sample_entropy(xs)))\n            except Exception:\n                pass\n    return float(np.mean(vals)) if vals else np.nan\n\ndef spectral_features(x, fs=1.0):\n    # safe nperseg\n    nperseg = min(256, max(8, len(x)))\n    f, Pxx = welch(x, fs=fs, nperseg=nperseg)\n    # spectral entropy fallback\n    if ant is not None:\n        try:\n            se = float(ant.spectral_entropy(x, sf=fs, method='welch', normalize=True))\n        except Exception:\n            P = Pxx / (Pxx.sum() + 1e-12)\n            se = float(-np.sum(P * np.log(P + 1e-12)))\n    else:\n        P = Pxx / (Pxx.sum() + 1e-12)\n        se = float(-np.sum(P * np.log(P + 1e-12)))\n    centroid = float(np.sum(f * Pxx) / (np.sum(Pxx) + 1e-12))\n    return se, centroid\n\ndef wavelet_energy(x, wavelet='db1', level=3):\n    if pywt is None:\n        return np.nan, np.nan\n    try:\n        coeffs = pywt.wavedec(x, wavelet, level=level)\n        energies = [np.sum(c**2) for c in coeffs if len(c) > 0]\n        return float(np.mean(energies)), float(np.std(energies))\n    except Exception:\n        return np.nan, np.nan\n\ndef lz_complexity(x):\n    if ant is None:\n        return np.nan\n    try:\n        sig = np.sign(x - np.nanmean(x)).astype(int)\n        return float(ant.lziv_complexity(sig))\n    except Exception:\n        return np.nan\n\ndef robust_stats(arr):\n    return {\n        'mean': float(np.nanmean(arr)),\n        'median': float(np.nanmedian(arr)),\n        'std': float(np.nanstd(arr)),\n        'iqr': float(np.nanpercentile(arr,75) - np.nanpercentile(arr,25))\n    }\n\n# --- cleaned main builder ---\ndef build_advanced_features(X_df, y_series):\n    \"\"\"\n    X_df: MultiIndex DataFrame (id, time) with columns ['value','period']\n    y_series: pd.Series indexed by id\n    Returns: X_features (DataFrame indexed by id), y_features (Series)\n    \"\"\"\n    rows = []\n    ids = []\n\n    for sid, df in X_df.groupby(level='id', sort=False):\n        df = df.dropna(subset=['value'])\n        before = df.loc[df['period']==0, 'value'].to_numpy(dtype=float)\n        after  = df.loc[df['period']==1, 'value'].to_numpy(dtype=float)\n\n        # skip too short segments\n        if len(before) < 8 or len(after) < 8:\n            continue\n\n        # basic stats once\n        b = robust_stats(before)\n        a = robust_stats(after)\n\n        feats = {\n            'b_mean': b['mean'], 'a_mean': a['mean'],\n            'b_median': b['median'], 'a_median': a['median'],\n            'b_std': b['std'], 'a_std': a['std'],\n            'b_iqr': b['iqr'], 'a_iqr': a['iqr'],\n        }\n\n        # diffs/ratios\n        feats['mean_diff'] = feats['a_mean'] - feats['b_mean']\n        feats['median_diff'] = feats['a_median'] - feats['b_median']\n        feats['std_diff'] = feats['a_std'] - feats['b_std']\n        feats['iqr_diff'] = feats['a_iqr'] - feats['b_iqr']\n        feats['std_ratio'] = (feats['a_std'] + 1e-9) / (feats['b_std'] + 1e-9)\n\n        # complexity: compute once per side (no duplicates)\n        feats['pe_m3_t1_diff'] = compute_permutation_entropy(after, m=3, tau=1) - compute_permutation_entropy(before, m=3, tau=1)\n        feats['pe_m5_t1_diff'] = compute_permutation_entropy(after, m=5, tau=1) - compute_permutation_entropy(before, m=5, tau=1)\n        feats['mse_diff'] = compute_multiscale_entropy(after) - compute_multiscale_entropy(before)\n\n        # distances/tests\n        try:\n            feats['emd'] = float(wasserstein_distance(before, after))\n        except:\n            feats['emd'] = np.nan\n        try:\n            feats['ks_stat'] = float(ks_2samp(before, after).statistic)\n        except:\n            feats['ks_stat'] = np.nan\n        try:\n            feats['mw_p'] = float(mannwhitneyu(before, after).pvalue)\n        except:\n            feats['mw_p'] = np.nan\n\n        # acf energy diff\n        try:\n            acf_b = np.nan_to_num(acf(before, nlags=20, fft=True))\n            acf_a = np.nan_to_num(acf(after, nlags=20, fft=True))\n            feats['acf_energy_diff'] = float(np.sum(acf_a**2) - np.sum(acf_b**2))\n        except:\n            feats['acf_energy_diff'] = np.nan\n\n        # spectral & wavelet\n        se_b, cent_b = spectral_features(before)\n        se_a, cent_a = spectral_features(after)\n        feats['spectral_entropy_diff'] = se_a - se_b\n        feats['spectral_centroid_diff'] = cent_a - cent_b\n\n        we_b_mean, we_b_std = wavelet_energy(before)\n        we_a_mean, we_a_std = wavelet_energy(after)\n        feats['wavelet_energy_diff'] = we_a_mean - we_b_mean\n\n        # hilbert instantaneous freq diff\n        try:\n            inst_b = np.mean(np.diff(np.unwrap(np.angle(hilbert(before)))))\n            inst_a = np.mean(np.diff(np.unwrap(np.angle(hilbert(after)))))\n            feats['hilbert_freq_diff'] = float(inst_a - inst_b)\n        except:\n            feats['hilbert_freq_diff'] = np.nan\n\n        # compression\n        feats['lz_diff'] = lz_complexity(after) - lz_complexity(before)\n\n        rows.append(feats)\n        ids.append(sid)\n\n    X_features = pd.DataFrame(rows, index=ids)\n    X_features.index.name = 'id'\n    X_features = X_features.replace([np.inf, -np.inf], np.nan).fillna(0)\n    y_features = y_series.loc[X_features.index].astype(int)\n\n    return X_features, y_features\n\n\ndef extract_features_series(df):\n    \"\"\"\n    df: DataFrame with columns ['value','period'] for a single id\n    returns: dict of features (same keys as build_advanced_features)\n    \"\"\"\n    df = df.dropna(subset=['value'])\n    before = df.loc[df['period']==0, 'value'].to_numpy(dtype=float)\n    after  = df.loc[df['period']==1, 'value'].to_numpy(dtype=float)\n\n    # skip too short segments\n    if len(before) < 8 or len(after) < 8:\n        return None\n\n    b = robust_stats(before)\n    a = robust_stats(after)\n\n    feats = {\n        'b_mean': b['mean'], 'a_mean': a['mean'],\n        'b_median': b['median'], 'a_median': a['median'],\n        'b_std': b['std'], 'a_std': a['std'],\n        'b_iqr': b['iqr'], 'a_iqr': a['iqr'],\n    }\n\n    feats['mean_diff']   = feats['a_mean'] - feats['b_mean']\n    feats['median_diff'] = feats['a_median'] - feats['b_median']\n    feats['std_diff']    = feats['a_std'] - feats['b_std']\n    feats['iqr_diff']    = feats['a_iqr'] - feats['b_iqr']\n    feats['std_ratio']   = (feats['a_std'] + 1e-9) / (feats['b_std'] + 1e-9)\n\n    # complexity\n    feats['pe_m3_t1_diff'] = compute_permutation_entropy(after, m=3, tau=1) - compute_permutation_entropy(before, m=3, tau=1)\n    feats['pe_m5_t1_diff'] = compute_permutation_entropy(after, m=5, tau=1) - compute_permutation_entropy(before, m=5, tau=1)\n    feats['mse_diff']      = compute_multiscale_entropy(after) - compute_multiscale_entropy(before)\n\n    # distances/tests\n    try:\n        feats['emd'] = float(wasserstein_distance(before, after))\n    except:\n        feats['emd'] = np.nan\n    try:\n        feats['ks_stat'] = float(ks_2samp(before, after).statistic)\n    except:\n        feats['ks_stat'] = np.nan\n    try:\n        feats['mw_p'] = float(mannwhitneyu(before, after).pvalue)\n    except:\n        feats['mw_p'] = np.nan\n\n    # acf energy diff\n    try:\n        acf_b = np.nan_to_num(acf(before, nlags=20, fft=True))\n        acf_a = np.nan_to_num(acf(after, nlags=20, fft=True))\n        feats['acf_energy_diff'] = float(np.sum(acf_a**2) - np.sum(acf_b**2))\n    except:\n        feats['acf_energy_diff'] = np.nan\n\n    # spectral & wavelet\n    se_b, cent_b = spectral_features(before)\n    se_a, cent_a = spectral_features(after)\n    feats['spectral_entropy_diff']  = se_a - se_b\n    feats['spectral_centroid_diff'] = cent_a - cent_b\n\n    we_b_mean, we_b_std = wavelet_energy(before)\n    we_a_mean, we_a_std = wavelet_energy(after)\n    feats['wavelet_energy_diff'] = we_a_mean - we_b_mean\n\n    # hilbert instantaneous freq diff\n    try:\n        inst_b = np.mean(np.diff(np.unwrap(np.angle(hilbert(before)))))\n        inst_a = np.mean(np.diff(np.unwrap(np.angle(hilbert(after)))))\n        feats['hilbert_freq_diff'] = float(inst_a - inst_b)\n    except:\n        feats['hilbert_freq_diff'] = np.nan\n\n    # compression\n    feats['lz_diff'] = lz_complexity(after) - lz_complexity(before)\n\n    return feats\n\n\n\ndef train(X_train: \"pd.DataFrame\", y_train: \"pd.Series\", model_directory_path: str):\n    \"\"\"\n    Crunch-style train function.\n    - X_train: MultiIndex DataFrame (id,time) with columns ['value','period']\n    - y_train: Series indexed by id\n    - model_directory_path: directory to save model.joblib\n    \"\"\"\n    os.makedirs(model_directory_path, exist_ok=True)\n    rng_seed = 42\n\n    # 1) Feature extraction (deterministic)\n    X_features, y_features = build_advanced_features(X_train, y_train)\n    print(f\"[train] Features built: {X_features.shape}, labels: {y_features.value_counts().to_dict()}\")\n\n    # 2) Ensure deterministic seeds in model definitions\n    # Build base models (MLP wrapped with scaler pipeline so scaler is saved inside)\n    from sklearn.pipeline import Pipeline\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n    from sklearn.linear_model import LogisticRegression\n    import lightgbm as lgb\n    import xgboost as xgb\n    from sklearn.neural_network import MLPClassifier\n\n    neg = len(y_features) - int(y_features.sum())\n    pos = int(y_features.sum())\n    pos_ratio = neg / (pos + 1e-9)\n\n    base_models = [\n        (\"lgb\", lgb.LGBMClassifier(\n            n_estimators=400, learning_rate=0.05, num_leaves=31,\n            subsample=0.8, colsample_bytree=0.8, random_state=rng_seed,\n            class_weight=\"balanced\"\n        )),\n        (\"xgb\", xgb.XGBClassifier(\n            n_estimators=400, learning_rate=0.05, max_depth=5,\n            subsample=0.8, colsample_bytree=0.8,\n            eval_metric=\"logloss\", use_label_encoder=False,\n            random_state=rng_seed, scale_pos_weight=pos_ratio\n        )),\n        (\"rf\", RandomForestClassifier(\n            n_estimators=300, max_depth=10, n_jobs=-1, random_state=rng_seed,\n            class_weight=\"balanced\"\n        )),\n        (\"mlp\", Pipeline([\n            (\"scaler\", StandardScaler()),\n            (\"mlp\", MLPClassifier(hidden_layer_sizes=(64,), max_iter=300,\n                                  random_state=rng_seed))\n        ])),\n        # you may add a logistic wrapper if you like\n    ]\n\n    # 3) Per-base-model CV to compute OOF preds (GroupKFold)\n    gkf = GroupKFold(n_splits=5)\n    # store OOF predictions for stacking diagnostics\n    oof_preds_per_model = {name: np.zeros(len(X_features)) for name, _ in base_models}\n    X_idx = np.arange(len(X_features))\n    groups = X_features.index\n\n    for name, model in base_models:\n        print(f\"[train] CV for base model: {name}\")\n        fold_preds = np.zeros(len(X_features))\n        for fold, (tr_idx, val_idx) in enumerate(gkf.split(X_features, y_features, groups)):\n            X_tr, X_val = X_features.iloc[tr_idx], X_features.iloc[val_idx]\n            y_tr, y_val = y_features.iloc[tr_idx], y_features.iloc[val_idx]\n\n            # fit\n            model.fit(X_tr, y_tr)\n            proba = model.predict_proba(X_val)[:, 1]\n            fold_preds[val_idx] = proba\n            print(f\"   fold {fold} | {name} ROC-AUC: {roc_auc_score(y_val, proba):.4f}\")\n\n        oof_score = roc_auc_score(y_features, fold_preds)\n        print(f\" [train] {name} OOF ROC-AUC: {oof_score:.4f}\")\n        oof_preds_per_model[name] = fold_preds.copy()\n\n    # 4) Fit calibrated base models on full data for stacking (optional calibration)\n    calibrated_estimators = []\n    for name, model in base_models:\n        print(f\"[train] Fitting & calibrating full model: {name}\")\n        model.fit(X_features, y_features)\n        calibrated = CalibratedClassifierCV(model, method=\"isotonic\", cv=3)\n        # CalibratedClassifierCV.fit will refit internally; this can be slow but yields calibrated probs.\n        calibrated.fit(X_features, y_features)\n        calibrated_estimators.append((name, calibrated))\n\n    # 5) Meta learner: LightGBM (non-linear)\n    meta = lgb.LGBMClassifier(n_estimators=300, learning_rate=0.05, num_leaves=15,\n                              subsample=0.8, colsample_bytree=0.8, random_state=rng_seed,\n                              class_weight=\"balanced\")\n\n    # 6) Build stacking classifier with passthrough (so original features are also available)\n    stack = StackingClassifier(\n        estimators=calibrated_estimators,\n        final_estimator=meta,\n        stack_method=\"predict_proba\",\n        passthrough=True,\n        cv=5,  # internal cv inside sklearn stacking for safety\n        n_jobs=-1\n    )\n\n    # Fit final stacking on full training features\n    stack.fit(X_features, y_features)\n    final_oof = roc_auc_score(y_features, stack.predict_proba(X_features)[:, 1])\n    print(f\"[train] Final stacking OOF ROC-AUC (on train features): {final_oof:.4f}\")\n\n    # 7) Save artifact: include feature columns and pipeline\n    artifact = {\n        \"feature_cols\": list(X_features.columns),\n        \"stacking_model\": stack,\n        \"oof_per_model\": oof_preds_per_model,\n        \"train_oof_score\": float(final_oof),\n        \"random_seed\": rng_seed\n    }\n    # âœ… Aur ab ye do lines daalo:\n    os.makedirs(model_directory_path, exist_ok=True)\n    joblib.dump(artifact, os.path.join(model_directory_path, \"model.joblib\"))\n    print(\"[train] Saved artifact to\", os.path.join(model_directory_path, \"model.joblib\"))\n    return\n\ndef infer(X_test, model_directory_path):\n    \"\"\"\n    Crunch-style infer generator. Yield once, then yield probabilities for each test series (one df at a time).\n    X_test: iterable of pd.DataFrame (single-series DataFrames) as Crunch expects.\n    \"\"\"\n    import os, joblib, pandas as pd\n\n    artifact = joblib.load(os.path.join(model_directory_path, \"model.joblib\"))\n    feature_cols = artifact[\"feature_cols\"]\n    stack = artifact[\"stacking_model\"]\n\n    # signal ready\n    yield\n\n    if X_test is None:\n        # safety check\n        return\n\n    # process each test DF (single series) and extract features then predict\n    for df in X_test:\n        feats = extract_features_series(df)\n        if feats is None:\n            yield 0.0\n            continue\n        x = pd.DataFrame([feats])\n        x = x.reindex(columns=feature_cols).fillna(0)\n        proba = float(stack.predict_proba(x)[0, 1])\n        yield proba\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-05T23:10:14.585548Z","iopub.execute_input":"2025-09-05T23:10:14.586021Z","iopub.status.idle":"2025-09-05T23:10:14.602723Z","shell.execute_reply.started":"2025-09-05T23:10:14.585993Z","shell.execute_reply":"2025-09-05T23:10:14.601629Z"}},"outputs":[{"name":"stdout","text":"Overwriting main.py\n[LightGBM] [Info] Number of positive: 1939, number of negative: 4728\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022435 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6057\n[LightGBM] [Info] Number of data points in the train set: 6667, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1939, number of negative: 4728\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002052 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6054\n[LightGBM] [Info] Number of data points in the train set: 6667, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1940, number of negative: 4728\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000920 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 6058\n[LightGBM] [Info] Number of data points in the train set: 6668, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n","output_type":"stream"}],"execution_count":96},{"cell_type":"markdown","source":"## Local testing\n\nTo make sure your `train()` and `infer()` function are working properly, you can call the `crunch.test()` function that will reproduce the cloud environment locally. <br />\nEven if it is not perfect, it should give you a quick idea if your model is working properly.","metadata":{"id":"1W0Kl9CA-0fU"}},{"cell_type":"code","source":"crunch.test(\n    # Uncomment to disable the train\n    #force_first_train=False,\n\n    # Uncomment to disable the determinism check\n    # no_determinism_check=True,\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tDZeP-4--0fU","outputId":"8bfdb1e2-446e-4cfe-9888-c9f07fb4aeab","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T23:10:22.441740Z","iopub.execute_input":"2025-09-05T23:10:22.442099Z","iopub.status.idle":"2025-09-05T23:20:32.576985Z","shell.execute_reply.started":"2025-09-05T23:10:22.442075Z","shell.execute_reply":"2025-09-05T23:20:32.575240Z"}},"outputs":[{"name":"stderr","text":"23:10:22 forbidden library: feature_builder  (request to whitelist: https://hub.crunchdao.com/competitions/structural-break/resources/whitelisted-libraries?requestAlias=feature_builder)\n23:10:22 \n23:10:22 started\n23:10:22 running local test\n23:10:22 internet access isn't restricted, no check will be done\n23:10:22 \n23:10:23 starting unstructured loop...\n23:10:23 executing - command=train\n","output_type":"stream"},{"name":"stdout","text":"data/X_train.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/X_train.parquet (204327238 bytes)\ndata/X_train.parquet: already exists, file length match\ndata/X_test.reduced.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/X_test.reduced.parquet (2380918 bytes)\ndata/X_test.reduced.parquet: already exists, file length match\ndata/y_train.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/y_train.parquet (61003 bytes)\ndata/y_train.parquet: already exists, file length match\ndata/y_test.reduced.parquet: download from https:crunchdao--competition--production.s3-accelerate.amazonaws.com/data-releases/146/y_test.reduced.parquet (2655 bytes)\ndata/y_test.reduced.parquet: already exists, file length match\n[train] Features built: (10001, 25), labels: {0: 7092, 1: 2909}\n[train] CV for base model: lgb\n[LightGBM] [Info] Number of positive: 2333, number of negative: 5667\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001304 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6058\n[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n[LightGBM] [Info] Start training from score 0.000000\n   fold 0 | lgb ROC-AUC: 0.6740\n[LightGBM] [Info] Number of positive: 2324, number of negative: 5677\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001553 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6057\n[LightGBM] [Info] Number of data points in the train set: 8001, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n[LightGBM] [Info] Start training from score 0.000000\n   fold 1 | lgb ROC-AUC: 0.6934\n[LightGBM] [Info] Number of positive: 2315, number of negative: 5686\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001215 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6058\n[LightGBM] [Info] Number of data points in the train set: 8001, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n   fold 2 | lgb ROC-AUC: 0.6798\n[LightGBM] [Info] Number of positive: 2353, number of negative: 5648\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001406 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6055\n[LightGBM] [Info] Number of data points in the train set: 8001, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n[LightGBM] [Info] Start training from score 0.000000\n   fold 3 | lgb ROC-AUC: 0.6815\n[LightGBM] [Info] Number of positive: 2311, number of negative: 5690\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001259 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6057\n[LightGBM] [Info] Number of data points in the train set: 8001, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n[LightGBM] [Info] Start training from score 0.000000\n   fold 4 | lgb ROC-AUC: 0.6960\n [train] lgb OOF ROC-AUC: 0.6847\n[train] CV for base model: xgb\n   fold 0 | xgb ROC-AUC: 0.6788\n   fold 1 | xgb ROC-AUC: 0.6976\n   fold 2 | xgb ROC-AUC: 0.6782\n   fold 3 | xgb ROC-AUC: 0.6776\n   fold 4 | xgb ROC-AUC: 0.6938\n [train] xgb OOF ROC-AUC: 0.6851\n[train] CV for base model: rf\n   fold 0 | rf ROC-AUC: 0.6758\n   fold 1 | rf ROC-AUC: 0.6958\n   fold 2 | rf ROC-AUC: 0.6826\n   fold 3 | rf ROC-AUC: 0.6824\n   fold 4 | rf ROC-AUC: 0.7005\n [train] rf OOF ROC-AUC: 0.6870\n[train] CV for base model: mlp\n   fold 0 | mlp ROC-AUC: 0.6344\n   fold 1 | mlp ROC-AUC: 0.6473\n   fold 2 | mlp ROC-AUC: 0.6228\n   fold 3 | mlp ROC-AUC: 0.6330\n   fold 4 | mlp ROC-AUC: 0.6390\n [train] mlp OOF ROC-AUC: 0.6346\n[train] Fitting & calibrating full model: lgb\n[LightGBM] [Info] Number of positive: 2909, number of negative: 7092\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001540 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6058\n[LightGBM] [Info] Number of data points in the train set: 10001, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1939, number of negative: 4728\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001432 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6057\n[LightGBM] [Info] Number of data points in the train set: 6667, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1939, number of negative: 4728\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001099 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6054\n[LightGBM] [Info] Number of data points in the train set: 6667, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1940, number of negative: 4728\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001133 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6058\n[LightGBM] [Info] Number of data points in the train set: 6668, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[train] Fitting & calibrating full model: xgb\n[train] Fitting & calibrating full model: rf\n[train] Fitting & calibrating full model: mlp\n","output_type":"stream"},{"name":"stderr","text":"2025-09-05 23:16:22.039976: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757114182.101438    8300 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2025-09-05 23:16:22.111600: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2025-09-05 23:16:22.112393: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nE0000 00:00:1757114182.119700    8300 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2025-09-05 23:16:22.161465: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757114182.192018    8302 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757114182.194782    8301 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757114182.209347    8302 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nE0000 00:00:1757114182.212020    8301 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1757114182.217065    8303 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1757114182.233302    8303 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1552, number of negative: 3782\n[LightGBM] [Info] Number of positive: 1551, number of negative: 3782\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007843 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6054\n[LightGBM] [Info] Number of positive: 1552, number of negative: 3782\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009720 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008952 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6054\n[LightGBM] [Info] Total Bins 6053\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] Number of positive: 1552, number of negative: 3782\n[LightGBM] [Info] Number of data points in the train set: 5333, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013610 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 6053\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1552, number of negative: 3782\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015864 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6053\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1551, number of negative: 3783\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014559 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Number of positive: 1551, number of negative: 3783\n[LightGBM] [Info] Total Bins 6053\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n[LightGBM] [Info] Start training from score 0.000000\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014754 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6053\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n[LightGBM] [Info] Start training from score 0.000000\n[LightGBM] [Info] Number of positive: 1551, number of negative: 3782\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010838 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6053\n[LightGBM] [Info] Number of data points in the train set: 5333, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1552, number of negative: 3782\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012064 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6054\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1551, number of negative: 3783\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008776 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6055\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n[LightGBM] [Info] Start training from score 0.000000\n[LightGBM] [Info] Number of positive: 1551, number of negative: 3783\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011869 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6054\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n[LightGBM] [Info] Start training from score 0.000000\n[LightGBM] [Info] Number of positive: 1552, number of negative: 3782\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005746 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6056\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1552, number of negative: 3782\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009891 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6056\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1551, number of negative: 3783\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003184 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6055\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n[LightGBM] [Info] Start training from score 0.000000\n[LightGBM] [Info] Number of positive: 1551, number of negative: 3783\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002673 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6054\n[LightGBM] [Info] Number of data points in the train set: 5334, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n[LightGBM] [Info] Start training from score 0.000000\n[LightGBM] [Info] Number of positive: 2909, number of negative: 7092\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001919 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 7078\n[LightGBM] [Info] Number of data points in the train set: 10001, number of used features: 28\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[train] Final stacking OOF ROC-AUC (on train features): 0.9709\n","output_type":"stream"},{"name":"stderr","text":"23:20:31 executing - command=infer\n","output_type":"stream"},{"name":"stdout","text":"[train] Saved artifact to resources/model.joblib\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"https://github.com/crunchdao/competitions/raw/refs/heads/master/competitions/structural-break/scoring/runner.py\", line 31, in run\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/runner/local.py\", line 559, in execute\n    result = utils.smart_call(\n             ^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/utils.py\", line 270, in smart_call\n    return function(**arguments)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"https://github.com/crunchdao/competitions/raw/refs/heads/master/competitions/structural-break/scoring/runner.py\", line 127, in infer\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/container.py\", line 187, in collect\n    y = next(iterator, sentinel)\n        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_36/3146772425.py\", line 145, in infer\n    for df in X_test_iterable:\nTypeError: 'NoneType' object is not iterable\n23:20:32 duration - time=00:10:09\n23:20:32 memory - before=\"2.89 GB\" after=\"2.47 GB\" consumed=\"-421969920 bytes\"\n","output_type":"stream"},{"name":"stdout","text":"Traceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/utils.py\", line 434, in limit_traceback\n    yield\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/utils.py\", line 268, in smart_call\n    return function(**arguments)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"https://github.com/crunchdao/competitions/raw/refs/heads/master/competitions/structural-break/scoring/runner.py\", line 31, in run\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/runner/local.py\", line 559, in execute\n    result = utils.smart_call(\n             ^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/utils.py\", line 270, in smart_call\n    return function(**arguments)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"https://github.com/crunchdao/competitions/raw/refs/heads/master/competitions/structural-break/scoring/runner.py\", line 127, in infer\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/container.py\", line 187, in collect\n    y = next(iterator, sentinel)\n        ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_36/3146772425.py\", line 145, in infer\n    for df in X_test_iterable:\nTypeError: 'NoneType' object is not iterable\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_36/419703265.py\", line 1, in <cell line: 0>\n    crunch.test(\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/inline.py\", line 182, in test\n    return tester.run(\n           ^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/tester.py\", line 72, in run\n    return runner.start()\n           ^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/runner/local.py\", line 66, in start\n    return super().start()\n           ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/runner/runner.py\", line 56, in start\n    result = self.start_unstructured()\n             ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/runner/local.py\", line 434, in start_unstructured\n    prediction = self.runner_module.run(\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/unstructured/module/runner.py\", line 35, in run\n    return execute.call_function(\n           ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/unstructured/execute.py\", line 21, in call_function\n    return utils.smart_call(\n           ^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/utils.py\", line 267, in smart_call\n    with _limit_traceback(1):\n  File \"/usr/lib/python3.11/contextlib.py\", line 158, in __exit__\n    self.gen.throw(typ, value, traceback)\n  File \"/usr/local/lib/python3.11/dist-packages/crunch/utils.py\", line 445, in limit_traceback\n    sys.exit(1)\nSystemExit: 1\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n    traceback_info = getframeinfo(tb, context)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/python3.11/inspect.py\", line 1671, in getframeinfo\n    lineno = frame.f_lineno\n             ^^^^^^^^^^^^^^\nAttributeError: 'tuple' object has no attribute 'f_lineno'\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/utils.py\u001b[0m in \u001b[0;36mlimit_traceback\u001b[0;34m(forward)\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSystemExit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAbort\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/utils.py\u001b[0m in \u001b[0;36msmart_call\u001b[0;34m(function, default_values, specific_values, log, logger, limit_traceback)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_limit_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mhttps://github.com/crunchdao/competitions/raw/refs/heads/master/competitions/structural-break/scoring/runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(context)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/runner/local.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, command, parameters, return_prediction)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m         result = utils.smart_call(\n\u001b[0m\u001b[1;32m    560\u001b[0m             \u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/utils.py\u001b[0m in \u001b[0;36msmart_call\u001b[0;34m(function, default_values, specific_values, log, logger, limit_traceback)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mhttps://github.com/crunchdao/competitions/raw/refs/heads/master/competitions/structural-break/scoring/runner.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(determinism_check)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/container.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self, expected_size)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msentinel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/3146772425.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(X_test_iterable, model_directory_path)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;31m# process each test DF (single series) and extract features then predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test_iterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_36/419703265.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m crunch.test(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Uncomment to disable the train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#force_first_train=False,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/inline.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, force_first_train, train_frequency, raise_abort, round_number, no_checks, no_determinism_check, read_kwargs, write_kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             return tester.run(\n\u001b[0m\u001b[1;32m    183\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_module\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/tester.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(user_module, runner_module, model_directory_path, force_first_train, train_frequency, round_number, competition, has_gpu, checks, no_determinism_check, read_kwargs, write_kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/runner/local.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/runner/runner.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"starting unstructured loop...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_unstructured\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/runner/local.py\u001b[0m in \u001b[0;36mstart_unstructured\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             prediction = self.runner_module.run(\n\u001b[0m\u001b[1;32m    435\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/unstructured/module/runner.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, context, data_directory_path, model_directory_path, limit_traceback)\u001b[0m\n\u001b[1;32m     34\u001b[0m     ) -> typing.Any:\n\u001b[0;32m---> 35\u001b[0;31m         return execute.call_function(\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_run_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/unstructured/execute.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(function, kwargs, print, limit_traceback)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         return utils.smart_call(\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/utils.py\u001b[0m in \u001b[0;36msmart_call\u001b[0;34m(function, default_values, specific_values, log, logger, limit_traceback)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlimit_traceback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_limit_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/crunch/utils.py\u001b[0m in \u001b[0;36mlimit_traceback\u001b[0;34m(forward)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSystemExit\u001b[0m: 1","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"],"ename":"TypeError","evalue":"object of type 'NoneType' has no len()","output_type":"error"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 1939, number of negative: 4728\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006581 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6057\n[LightGBM] [Info] Number of data points in the train set: 6667, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1939, number of negative: 4728\n[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024779 seconds.\nYou can set `force_col_wise=true` to remove the overhead.\n[LightGBM] [Info] Total Bins 6054\n[LightGBM] [Info] Number of data points in the train set: 6667, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n[LightGBM] [Info] Number of positive: 1940, number of negative: 4728\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003984 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 6058\n[LightGBM] [Info] Number of data points in the train set: 6668, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n[LightGBM] [Info] Start training from score -0.000000\n","output_type":"stream"}],"execution_count":97},{"cell_type":"markdown","source":"## Results\n\nOnce the local tester is done, you can preview the result stored in `data/prediction.parquet`.","metadata":{"id":"bV_5CKs--0fU"}},{"cell_type":"code","source":"prediction = pd.read_parquet(\"data/prediction.parquet\")\nprediction","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":238},"id":"ly5q68sA-0fU","outputId":"4ab7c035-6bdc-41dc-85b5-c11c8ddc6d1a","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T21:17:06.378024Z","iopub.execute_input":"2025-09-05T21:17:06.381182Z","iopub.status.idle":"2025-09-05T21:17:06.465750Z","shell.execute_reply.started":"2025-09-05T21:17:06.381126Z","shell.execute_reply":"2025-09-05T21:17:06.463753Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/3034219019.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/prediction.parquet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m     \u001b[0mcheck_dtype_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m     return impl.read(\n\u001b[0m\u001b[1;32m    668\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mto_pandas_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"split_blocks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         path_or_handle, handles, filesystem = _get_path_or_handle(\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mfilesystem\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;31m# fsspec resources can also point to directories\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# this branch is used for example when reading from non-fsspec URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         handles = get_handle(\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0mpath_or_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/prediction.parquet'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'data/prediction.parquet'","output_type":"error"}],"execution_count":80},{"cell_type":"markdown","source":"### Local scoring\n\nYou can call the function that the system uses to estimate your score locally.","metadata":{"id":"1oP-NLGh-0fU"}},{"cell_type":"code","source":"# Load the targets\ntarget = pd.read_parquet(\"data/y_test.reduced.parquet\")[\"structural_breakpoint\"]\n\n# Call the scoring function\nsklearn.metrics.roc_auc_score(\n    target,\n    prediction,\n)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RyCrjpzv-0fU","outputId":"4dd5e952-db2d-465f-b231-7bf606161b19","trusted":true,"execution":{"iopub.status.busy":"2025-09-05T22:24:33.216475Z","iopub.execute_input":"2025-09-05T22:24:33.216880Z","iopub.status.idle":"2025-09-05T22:24:33.252861Z","shell.execute_reply.started":"2025-09-05T22:24:33.216855Z","shell.execute_reply":"2025-09-05T22:24:33.249863Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_36/1678923823.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m sklearn.metrics.roc_auc_score(\n\u001b[1;32m      6\u001b[0m     \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n","\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"],"ename":"NameError","evalue":"name 'prediction' is not defined","output_type":"error"}],"execution_count":86},{"cell_type":"markdown","source":"# Submit your Notebook\n\nTo submit your work, you must:\n1. Download your Notebook from Kaggle\n2. Upload it to the platform\n3. Create a run to validate it\n\n### >> https://hub.crunchdao.com/competitions/structural-break/submit/notebook\n\n![Download and Submit Notebook](https://raw.githubusercontent.com/crunchdao/competitions/refs/heads/master/documentation/animations/download-and-submit-notebook-on-kaggle.gif)","metadata":{"id":"3AE1i3pR-0fV"}}]}